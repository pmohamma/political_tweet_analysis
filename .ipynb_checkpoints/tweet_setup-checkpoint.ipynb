{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tweet import *\n",
    "from poll import *\n",
    "from candidate import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tweepy\n",
    "import json\n",
    "import calendar\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting polls\n",
    "# all code copied over from pollster_setup.ipnyb\n",
    "\n",
    "f_polls = open(\"dist/poll_data.json\")\n",
    "data = json.load(f_polls)\n",
    "\n",
    "polls = [None](len(data))\n",
    "for i in range(len(data)):\n",
    "    polls[i] = (Poll(data[i]))\n",
    "    \n",
    "candidate_set = set()\n",
    "for p in polls_set:\n",
    "    p.update_candidates(candidate_set)\n",
    "    \n",
    "polls.sort(key = lambda x: x.end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Fill this in\n",
    "\n",
    "consumer_key = \"BeC8UJbqCHyX6pTWAvEvvIcGJ\"\n",
    "consumer_secret = \"IwEzqplLUKar6MFZ7l828tLbEpxG3ObD49llOSPJ6Y6phKzVYT\"\n",
    "access_token = \"727703646331240448-31ZFnJzKYfDcHh3HIgBhd1FfU3W7VaO\"\n",
    "access_token_secret = \"GprFSIZ18ukkn9lZb7INfEn78miwkXzWpkzyJ6ocLAg6J\"\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_abbrs = dict((v,k) for k,v in enumerate(calendar.month_abbr))\n",
    "\n",
    "most_recent_rankings = ['bennet',\n",
    "                         'castro',\n",
    "                         'booker',\n",
    "                         'klobuchar',\n",
    "                         'gabbard',\n",
    "                         'yang',\n",
    "                         'harris',\n",
    "                         'buttigieg',\n",
    "                         'warren',\n",
    "                         'sanders',\n",
    "                         'biden']\n",
    "\n",
    "last_name_to_handle = {'bennet': 'MichaelBennet',\n",
    "                         'castro': 'JulianCastro',\n",
    "                         'booker': 'CoryBooker',\n",
    "                         'klobuchar': 'amyklobuchar',\n",
    "                         'gabbard': 'TulsiGabbard',\n",
    "                         'yang': 'AndrewYang',\n",
    "                         'harris': 'KamalaHarris',\n",
    "                         'buttigieg': 'PeteButtigieg',\n",
    "                         'warren': 'ewarren',\n",
    "                         'sanders': 'BernieSanders',\n",
    "                         'biden': 'JoeBiden'}\n",
    "\n",
    "handle_to_last_name = {}\n",
    "for i in last_name_to_handle:\n",
    "    handle_to_last_name[i] = last_name_to_handle[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweet_time(time_str):\n",
    "    global month_abbrs\n",
    "    time_lst = time_str.split(\" \")\n",
    "    year = int(time_lst[-1])\n",
    "    day = int(time_lst[2])\n",
    "    month = month_abbrs[time_lst[1]]\n",
    "    return datetime.date(year, month, day)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AndrewYang\n",
      "2019-12-08 23:31:00\n",
      "2019-12-08 19:16:17\n",
      "2019-12-08 15:11:07\n",
      "2019-12-08 00:08:30\n",
      "2019-12-07 17:22:14\n",
      "2019-12-07 00:21:10\n",
      "2019-12-06 14:53:44\n",
      "2019-12-05 22:46:20\n",
      "2019-12-05 14:15:44\n",
      "2019-12-05 01:36:24\n",
      "2019-12-04 20:42:18\n",
      "2019-12-04 04:45:11\n",
      "2019-12-03 23:21:39\n",
      "2019-12-03 17:23:20\n",
      "2019-12-02 23:40:50\n",
      "2019-12-02 19:47:24\n",
      "2019-12-02 03:09:53\n",
      "2019-12-01 23:02:44\n",
      "2019-12-01 22:58:06\n",
      "2019-12-01 20:23:40\n",
      "2019-12-01 03:42:00\n",
      "2019-12-01 01:14:52\n",
      "2019-11-30 16:35:13\n",
      "2019-11-29 17:11:01\n",
      "2019-11-28 23:50:56\n",
      "2019-11-28 21:35:34\n",
      "2019-11-28 15:34:23\n",
      "2019-11-27 21:07:05\n",
      "2019-11-27 13:23:06\n",
      "2019-11-27 04:29:17\n",
      "2019-11-26 22:34:30\n",
      "2019-11-26 14:21:34\n",
      "2019-11-26 01:48:16\n",
      "2019-11-25 21:48:35\n",
      "2019-11-25 12:56:38\n",
      "2019-11-24 22:13:54\n",
      "2019-11-24 05:29:45\n",
      "2019-11-23 14:44:21\n",
      "2019-11-22 21:01:24\n",
      "2019-11-22 04:57:12\n",
      "2019-11-21 19:10:36\n",
      "2019-11-21 04:43:46\n",
      "2019-11-21 03:05:16\n",
      "2019-11-20 16:45:18\n",
      "2019-11-19 17:46:01\n",
      "2019-11-18 22:30:45\n",
      "2019-11-18 04:19:44\n",
      "2019-11-17 04:57:23\n",
      "2019-11-16 23:43:31\n",
      "2019-11-16 01:49:04\n",
      "2019-11-15 14:36:04\n",
      "2019-11-14 19:51:30\n",
      "2019-11-14 03:32:18\n",
      "2019-11-13 20:38:17\n",
      "2019-11-13 00:09:08\n",
      "2019-11-12 17:31:45\n",
      "2019-11-11 23:35:51\n",
      "2019-11-11 03:31:06\n",
      "2019-11-10 17:00:18\n",
      "2019-11-10 00:37:26\n",
      "2019-11-09 15:49:49\n",
      "2019-11-09 02:08:16\n",
      "2019-11-08 14:55:28\n",
      "2019-11-08 02:02:23\n",
      "2019-11-07 12:10:27\n",
      "2019-11-06 20:22:20\n",
      "2019-11-06 13:29:25\n",
      "2019-11-05 21:55:00\n",
      "2019-11-05 15:18:40\n",
      "2019-11-05 03:40:38\n",
      "2019-11-04 17:26:51\n",
      "2019-11-04 03:20:06\n",
      "2019-11-03 14:04:45\n",
      "2019-11-02 18:33:52\n",
      "2019-11-02 01:56:06\n",
      "2019-11-01 19:13:59\n",
      "2019-11-01 12:22:29\n",
      "2019-11-01 02:00:37\n",
      "2019-11-01 00:08:37\n",
      "2019-10-31 20:54:18\n",
      "2019-10-31 01:51:37\n",
      "2019-10-30 20:08:27\n",
      "2019-10-30 02:09:16\n",
      "2019-10-29 16:06:56\n",
      "2019-10-28 20:55:29\n",
      "2019-10-28 12:55:44\n",
      "2019-10-27 23:34:18\n",
      "2019-10-27 04:05:30\n",
      "2019-10-26 21:50:24\n",
      "2019-10-26 18:20:45\n",
      "2019-10-26 04:18:10\n",
      "2019-10-25 20:36:56\n",
      "2019-10-25 01:07:53\n",
      "2019-10-24 14:43:27\n",
      "2019-10-24 00:56:49\n",
      "2019-10-23 02:44:11\n",
      "2019-10-22 16:37:46\n",
      "2019-10-22 01:00:28\n",
      "2019-10-21 10:52:54\n",
      "2019-10-20 21:44:11\n",
      "2019-10-20 01:31:48\n",
      "2019-10-19 14:27:18\n",
      "2019-10-18 22:47:39\n",
      "2019-10-18 20:27:50\n",
      "2019-10-18 03:56:24\n",
      "2019-10-17 18:55:21\n",
      "2019-10-16 21:59:34\n",
      "2019-10-16 06:31:34\n",
      "2019-10-16 01:45:50\n",
      "2019-10-15 21:39:53\n",
      "2019-10-14 15:18:30\n",
      "2019-10-13 17:55:12\n",
      "2019-10-12 23:05:22\n",
      "2019-10-12 18:33:19\n",
      "2019-10-11 18:31:02\n",
      "2019-10-10 22:00:31\n",
      "2019-10-10 11:15:48\n",
      "2019-10-09 23:20:04\n",
      "2019-10-09 12:33:11\n",
      "2019-10-08 03:36:30\n",
      "2019-10-07 18:38:58\n",
      "2019-10-07 00:41:09\n",
      "2019-10-06 00:35:03\n",
      "2019-10-05 21:44:47\n",
      "2019-10-05 18:34:16\n",
      "2019-10-05 04:08:04\n",
      "2019-10-04 20:47:42\n",
      "2019-10-04 14:37:06\n",
      "2019-10-03 17:29:58\n",
      "2019-10-03 05:45:30\n",
      "2019-10-02 21:36:02\n",
      "2019-10-02 12:39:24\n",
      "2019-10-01 13:37:52\n",
      "2019-09-30 15:40:57\n",
      "2019-09-29 23:05:01\n",
      "2019-09-29 04:11:10\n",
      "2019-09-28 22:19:19\n",
      "2019-09-27 22:10:18\n",
      "2019-09-27 14:23:03\n",
      "2019-09-26 21:59:23\n",
      "2019-09-26 18:23:41\n",
      "2019-09-26 02:53:41\n",
      "2019-09-25 01:02:58\n",
      "2019-09-24 02:36:24\n",
      "2019-09-23 18:02:56\n",
      "2019-09-22 22:54:11\n",
      "2019-09-22 01:22:30\n",
      "2019-09-21 13:24:57\n",
      "2019-09-20 20:18:16\n",
      "2019-09-20 01:05:49\n",
      "2019-09-19 03:11:41\n",
      "2019-09-18 13:50:51\n",
      "2019-09-17 21:19:31\n",
      "2019-09-17 00:17:04\n",
      "2019-09-16 13:24:06\n",
      "2019-09-15 17:30:14\n",
      "2019-09-15 02:46:37\n",
      "2019-09-14 13:30:57\n",
      "2019-09-13 17:06:02\n",
      "2019-09-13 01:24:09\n",
      "ewarren\n",
      "2019-12-08 01:32:03\n",
      "2019-12-06 21:50:05\n",
      "2019-12-05 04:29:59\n",
      "2019-12-03 22:27:06\n",
      "2019-12-02 18:37:51\n",
      "2019-11-30 20:46:57\n",
      "2019-11-28 18:17:20\n",
      "2019-11-26 20:45:08\n",
      "2019-11-24 23:49:12\n",
      "2019-11-23 01:45:58\n",
      "2019-11-22 00:32:57\n",
      "2019-11-22 00:09:59\n",
      "2019-11-21 23:01:02\n",
      "2019-11-21 04:39:52\n",
      "2019-11-21 02:24:51\n",
      "2019-11-20 15:52:13\n",
      "2019-11-19 16:50:27\n",
      "2019-11-18 23:14:06\n",
      "2019-11-18 00:39:08\n",
      "2019-11-16 14:30:26\n",
      "2019-11-15 19:02:17\n",
      "2019-11-15 02:10:10\n",
      "2019-11-13 23:04:49\n",
      "2019-11-12 18:28:36\n",
      "2019-11-11 02:48:50\n",
      "2019-11-09 03:22:31\n",
      "2019-11-08 03:13:48\n",
      "2019-11-07 01:17:34\n",
      "2019-11-06 03:43:01\n",
      "2019-11-05 14:41:47\n",
      "2019-11-04 23:05:40\n",
      "2019-11-02 16:34:43\n",
      "2019-11-01 20:52:14\n",
      "2019-11-01 12:40:43\n",
      "2019-10-30 22:34:16\n",
      "2019-10-29 13:01:37\n",
      "2019-10-27 22:28:56\n",
      "2019-10-26 01:05:11\n",
      "2019-10-24 15:35:23\n",
      "2019-10-22 23:59:02\n",
      "2019-10-22 00:50:21\n",
      "2019-10-21 13:00:31\n",
      "2019-10-19 19:39:27\n",
      "2019-10-18 01:38:38\n",
      "2019-10-17 00:43:10\n",
      "2019-10-16 03:17:31\n",
      "2019-10-16 00:45:41\n",
      "2019-10-15 16:34:06\n",
      "2019-10-14 19:47:48\n",
      "2019-10-12 14:01:38\n",
      "2019-10-11 01:12:28\n",
      "2019-10-10 10:22:10\n",
      "2019-10-09 18:23:33\n",
      "2019-10-09 04:06:20\n",
      "2019-10-07 23:21:36\n",
      "2019-10-06 23:02:52\n",
      "2019-10-04 19:15:26\n",
      "2019-10-03 18:41:59\n",
      "2019-10-03 00:17:28\n",
      "2019-10-02 13:00:49\n",
      "2019-10-01 17:21:50\n",
      "2019-09-30 17:01:23\n",
      "2019-09-29 01:20:11\n",
      "2019-09-27 22:44:52\n",
      "2019-09-27 13:00:39\n",
      "2019-09-26 20:54:08\n",
      "2019-09-25 19:06:10\n",
      "2019-09-23 23:53:40\n",
      "2019-09-22 15:31:41\n",
      "2019-09-21 01:46:38\n",
      "2019-09-20 00:10:55\n",
      "2019-09-18 20:47:25\n",
      "2019-09-17 18:50:32\n",
      "2019-09-16 16:52:41\n",
      "2019-09-15 14:31:07\n",
      "2019-09-13 13:53:20\n",
      "2019-09-13 00:55:34\n",
      "PeteButtigieg\n",
      "2019-12-05 16:27:47\n",
      "2019-12-03 12:29:31\n",
      "2019-11-25 21:25:53\n",
      "2019-11-21 05:24:26\n",
      "2019-11-21 02:43:16\n",
      "2019-11-18 20:54:45\n",
      "2019-11-15 13:55:36\n",
      "2019-11-12 02:40:25\n",
      "2019-11-07 20:54:03\n",
      "2019-11-04 21:26:41\n",
      "2019-11-01 23:12:13\n",
      "2019-10-31 01:53:17\n",
      "2019-10-26 01:46:03\n",
      "2019-10-24 15:21:12\n",
      "2019-10-21 20:32:26\n",
      "2019-10-16 20:24:10\n",
      "2019-10-16 01:03:23\n",
      "2019-10-15 01:13:51\n",
      "2019-10-11 15:33:15\n",
      "2019-10-08 19:46:02\n",
      "2019-10-04 20:22:40\n",
      "2019-10-01 21:35:52\n",
      "2019-09-29 19:54:09\n",
      "2019-09-25 18:00:07\n",
      "2019-09-23 22:09:27\n",
      "2019-09-23 21:30:04\n",
      "2019-09-21 21:35:15\n",
      "2019-09-19 23:50:53\n",
      "2019-09-17 12:06:34\n",
      "2019-09-13 02:50:44\n",
      "2019-09-13 00:50:53\n",
      "BernieSanders\n",
      "2019-12-08 00:57:16\n",
      "2019-12-07 02:45:00\n",
      "2019-12-06 15:21:40\n",
      "2019-12-05 15:47:37\n",
      "2019-12-03 22:25:24\n",
      "2019-12-01 22:17:42\n",
      "2019-11-28 18:53:11\n",
      "2019-11-27 22:44:20\n",
      "2019-11-26 20:48:13\n",
      "2019-11-25 17:18:20\n",
      "2019-11-23 18:14:03\n",
      "2019-11-22 01:40:00\n",
      "2019-11-21 15:47:42\n",
      "2019-11-21 02:10:11\n",
      "2019-11-20 14:03:29\n",
      "2019-11-18 20:35:56\n",
      "2019-11-17 03:43:47\n",
      "2019-11-15 21:56:26\n",
      "2019-11-14 20:33:35\n",
      "2019-11-13 16:09:56\n",
      "2019-11-12 14:19:42\n",
      "2019-11-10 18:51:08\n",
      "2019-11-09 19:53:40\n",
      "2019-11-08 20:58:21\n",
      "2019-11-07 21:01:24\n",
      "2019-11-06 23:11:29\n",
      "2019-11-05 12:07:31\n",
      "2019-11-04 01:16:18\n",
      "2019-11-02 16:34:13\n",
      "2019-10-31 18:45:00\n",
      "2019-10-30 18:59:31\n",
      "2019-10-29 14:36:01\n",
      "2019-10-28 13:04:06\n",
      "2019-10-27 18:49:10\n",
      "2019-10-25 23:30:00\n",
      "2019-10-25 15:27:05\n",
      "2019-10-24 19:21:59\n",
      "2019-10-23 17:20:28\n",
      "2019-10-21 20:40:20\n",
      "2019-10-19 21:56:09\n",
      "2019-10-19 18:32:40\n",
      "2019-10-19 17:20:44\n",
      "2019-10-18 23:30:00\n",
      "2019-10-17 19:43:36\n",
      "2019-10-16 01:59:41\n",
      "2019-10-15 22:49:00\n",
      "2019-10-14 17:01:46\n",
      "2019-10-12 21:10:16\n",
      "2019-10-10 22:22:00\n",
      "2019-10-08 13:56:43\n",
      "2019-10-05 14:46:37\n",
      "2019-10-01 21:56:03\n",
      "2019-10-01 11:21:56\n",
      "2019-09-29 21:50:33\n",
      "2019-09-28 21:06:10\n",
      "2019-09-27 16:56:29\n",
      "2019-09-26 15:01:49\n",
      "2019-09-25 13:24:03\n",
      "2019-09-24 13:15:34\n",
      "2019-09-22 22:33:25\n",
      "2019-09-21 19:17:24\n",
      "2019-09-21 13:34:18\n",
      "2019-09-20 14:02:34\n",
      "2019-09-19 13:51:06\n",
      "2019-09-18 01:46:55\n",
      "2019-09-17 13:50:15\n",
      "2019-09-15 21:15:00\n",
      "2019-09-14 19:33:00\n",
      "2019-09-13 18:57:49\n",
      "MichaelBennet\n",
      "2019-12-09 13:37:09\n",
      "2019-12-07 15:44:07\n",
      "2019-12-06 03:08:31\n",
      "2019-12-05 03:18:55\n",
      "2019-12-03 22:21:16\n",
      "2019-12-02 01:37:57\n",
      "2019-11-27 17:42:16\n",
      "2019-11-24 13:59:43\n",
      "2019-11-21 04:53:41\n",
      "2019-11-20 23:44:28\n",
      "2019-11-20 17:31:36\n",
      "2019-11-17 20:44:10\n",
      "2019-11-16 18:25:20\n",
      "2019-11-14 19:48:12\n",
      "2019-11-13 18:15:13\n",
      "2019-11-11 22:51:01\n",
      "2019-11-09 16:06:23\n",
      "2019-11-08 21:19:18\n",
      "2019-11-07 12:04:39\n",
      "2019-11-06 18:51:02\n",
      "2019-11-06 03:07:06\n",
      "2019-11-04 16:19:05\n",
      "2019-11-02 16:16:26\n",
      "2019-11-01 14:34:13\n",
      "2019-10-28 18:39:17\n",
      "2019-10-25 20:14:07\n",
      "2019-10-25 12:37:47\n",
      "2019-10-23 22:03:47\n",
      "2019-10-21 21:01:26\n",
      "2019-10-20 14:20:10\n",
      "2019-10-17 20:33:19\n",
      "2019-10-16 16:48:54\n",
      "2019-10-15 12:01:27\n",
      "2019-10-13 03:27:10\n",
      "2019-10-10 18:38:48\n",
      "2019-10-09 15:11:02\n",
      "2019-10-08 02:34:27\n",
      "2019-10-05 22:40:45\n",
      "2019-10-04 12:06:09\n",
      "2019-09-28 13:03:25\n",
      "2019-09-22 16:07:45\n",
      "2019-09-21 19:22:33\n",
      "2019-09-20 14:03:24\n",
      "2019-09-19 14:32:12\n",
      "2019-09-17 00:32:30\n",
      "2019-09-14 21:36:58\n",
      "2019-09-13 21:37:37\n",
      "amyklobuchar\n",
      "2019-12-07 15:42:24\n",
      "2019-12-05 15:00:45\n",
      "2019-12-02 22:38:01\n",
      "2019-11-30 18:25:21\n",
      "2019-11-27 20:11:28\n",
      "2019-11-25 00:43:33\n",
      "2019-11-22 16:47:44\n",
      "2019-11-21 03:37:28\n",
      "2019-11-19 14:59:34\n",
      "2019-11-17 04:00:29\n",
      "2019-11-15 19:13:57\n",
      "2019-11-13 17:16:08\n",
      "2019-11-09 21:41:55\n",
      "2019-11-07 14:17:57\n",
      "2019-11-05 19:16:07\n",
      "2019-11-02 21:39:38\n",
      "2019-10-31 23:34:15\n",
      "2019-10-29 08:50:29\n",
      "2019-10-26 03:20:37\n",
      "2019-10-23 18:30:11\n",
      "2019-10-21 09:28:33\n",
      "2019-10-18 18:41:25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-16 21:35:59\n",
      "2019-10-15 23:55:11\n",
      "2019-10-12 18:35:34\n",
      "2019-10-10 10:38:55\n",
      "2019-10-07 02:44:14\n",
      "2019-10-05 00:23:33\n",
      "2019-10-02 22:34:04\n",
      "2019-09-30 01:11:15\n",
      "2019-09-27 03:22:07\n",
      "2019-09-24 12:34:21\n",
      "2019-09-21 13:22:57\n",
      "2019-09-19 02:36:52\n",
      "2019-09-16 19:57:29\n",
      "2019-09-13 23:02:22\n",
      "2019-09-13 00:53:07\n",
      "KamalaHarris\n",
      "2019-12-01 02:10:00\n",
      "2019-11-27 19:53:00\n",
      "2019-11-25 17:00:30\n",
      "2019-11-22 20:36:00\n",
      "2019-11-21 03:52:55\n",
      "2019-11-20 02:42:00\n",
      "2019-11-18 03:28:16\n",
      "2019-11-16 03:39:00\n",
      "2019-11-14 14:54:51\n",
      "2019-11-12 16:01:37\n",
      "2019-11-09 19:42:02\n",
      "2019-11-07 18:48:01\n",
      "2019-11-06 04:53:08\n",
      "2019-11-04 19:23:23\n",
      "2019-11-02 17:05:01\n",
      "2019-11-01 17:45:01\n",
      "2019-10-30 20:32:22\n",
      "2019-10-29 00:02:00\n",
      "2019-10-27 12:29:00\n",
      "2019-10-24 21:17:01\n",
      "2019-10-23 00:02:00\n",
      "2019-10-20 13:15:02\n",
      "2019-10-18 00:03:00\n",
      "2019-10-16 18:28:50\n",
      "2019-10-16 00:19:23\n",
      "2019-10-14 00:05:00\n",
      "2019-10-12 01:13:28\n",
      "2019-10-10 21:47:05\n",
      "2019-10-09 02:52:40\n",
      "2019-10-07 14:55:01\n",
      "2019-10-04 20:36:00\n",
      "2019-10-03 00:42:57\n",
      "2019-10-01 17:40:01\n",
      "2019-09-29 16:12:01\n",
      "2019-09-27 17:36:01\n",
      "2019-09-25 20:38:35\n",
      "2019-09-23 20:07:03\n",
      "2019-09-21 17:22:00\n",
      "2019-09-19 20:43:01\n",
      "2019-09-17 19:15:22\n",
      "2019-09-15 15:03:19\n",
      "2019-09-13 03:40:43\n",
      "TulsiGabbard\n",
      "2019-12-03 16:53:02\n",
      "2019-11-30 01:42:18\n",
      "2019-11-28 20:55:15\n",
      "2019-11-27 00:54:39\n",
      "2019-11-27 00:18:48\n",
      "2019-11-26 20:57:34\n",
      "2019-11-21 04:44:23\n",
      "2019-11-13 18:04:41\n",
      "2019-11-10 14:15:11\n",
      "2019-11-08 22:29:27\n",
      "2019-11-04 23:34:09\n",
      "2019-10-30 10:18:44\n",
      "2019-10-25 12:26:05\n",
      "2019-10-21 11:02:58\n",
      "2019-10-18 20:20:43\n",
      "2019-10-16 05:45:32\n",
      "2019-10-11 23:02:14\n",
      "2019-10-08 05:31:07\n",
      "2019-10-01 12:52:00\n",
      "2019-09-23 02:44:52\n",
      "2019-09-17 23:17:20\n",
      "2019-09-13 23:44:58\n",
      "JulianCastro\n",
      "2019-12-07 13:46:44\n",
      "2019-12-06 03:45:06\n",
      "2019-12-05 14:37:03\n",
      "2019-12-04 03:21:26\n",
      "2019-12-03 18:31:48\n",
      "2019-12-02 01:26:32\n",
      "2019-11-28 16:25:29\n",
      "2019-11-27 13:58:00\n",
      "2019-11-25 17:49:37\n",
      "2019-11-23 20:23:50\n",
      "2019-11-22 17:54:37\n",
      "2019-11-21 17:53:30\n",
      "2019-11-21 03:33:27\n",
      "2019-11-21 02:11:06\n",
      "2019-11-20 19:05:05\n",
      "2019-11-20 01:14:24\n",
      "2019-11-19 15:14:43\n",
      "2019-11-18 19:40:35\n",
      "2019-11-17 21:34:27\n",
      "2019-11-16 00:03:31\n",
      "2019-11-14 23:41:10\n",
      "2019-11-14 15:33:32\n",
      "2019-11-13 19:09:22\n",
      "2019-11-12 19:51:02\n",
      "2019-11-12 00:19:09\n",
      "2019-11-10 21:10:16\n",
      "2019-11-08 02:16:21\n",
      "2019-11-06 22:17:48\n",
      "2019-11-06 01:38:29\n",
      "2019-11-04 20:32:20\n",
      "2019-11-02 03:42:27\n",
      "2019-11-01 18:45:03\n",
      "2019-10-31 19:40:43\n",
      "2019-10-30 20:43:57\n",
      "2019-10-29 19:50:17\n",
      "2019-10-28 19:39:47\n",
      "2019-10-27 20:05:51\n",
      "2019-10-26 19:01:59\n",
      "2019-10-25 13:47:22\n",
      "2019-10-24 17:15:26\n",
      "2019-10-24 14:15:40\n",
      "2019-10-23 22:10:01\n",
      "2019-10-23 15:37:58\n",
      "2019-10-22 14:14:29\n",
      "2019-10-21 18:44:17\n",
      "2019-10-20 20:00:04\n",
      "2019-10-17 20:25:31\n",
      "2019-10-16 15:32:44\n",
      "2019-10-16 03:24:10\n",
      "2019-10-16 02:01:56\n",
      "2019-10-16 01:05:31\n",
      "2019-10-15 13:06:02\n",
      "2019-10-14 13:20:59\n",
      "2019-10-11 04:48:00\n",
      "2019-10-10 17:37:41\n",
      "2019-10-10 01:56:37\n",
      "2019-10-10 00:10:19\n",
      "2019-10-08 16:08:15\n",
      "2019-10-07 19:19:28\n",
      "2019-10-06 13:48:03\n",
      "2019-10-04 22:11:13\n",
      "2019-10-04 14:32:58\n",
      "2019-10-02 20:06:51\n",
      "2019-10-02 14:45:12\n",
      "2019-10-01 03:48:42\n",
      "2019-09-28 22:15:57\n",
      "2019-09-27 21:22:21\n",
      "2019-09-26 23:30:30\n",
      "2019-09-26 00:30:00\n",
      "2019-09-24 18:35:51\n",
      "2019-09-22 23:03:23\n",
      "2019-09-21 19:23:46\n",
      "2019-09-21 02:09:25\n",
      "2019-09-19 22:37:29\n",
      "2019-09-19 16:38:45\n",
      "2019-09-18 00:48:48\n",
      "2019-09-16 21:32:39\n",
      "2019-09-14 18:37:27\n",
      "2019-09-13 03:42:04\n",
      "2019-09-13 00:10:44\n",
      "CoryBooker\n",
      "2019-12-07 00:16:01\n",
      "2019-12-05 17:17:12\n",
      "2019-12-04 02:43:19\n",
      "2019-12-02 15:30:23\n",
      "2019-11-27 18:09:27\n",
      "2019-11-24 18:05:10\n",
      "2019-11-22 17:37:50\n",
      "2019-11-21 04:49:31\n",
      "2019-11-21 02:50:12\n",
      "2019-11-20 15:16:18\n",
      "2019-11-16 18:58:39\n",
      "2019-11-13 15:38:34\n",
      "2019-11-09 01:05:49\n",
      "2019-11-06 17:10:01\n",
      "2019-11-04 00:21:46\n",
      "2019-11-01 20:01:41\n",
      "2019-10-30 13:59:24\n",
      "2019-10-26 21:54:16\n",
      "2019-10-24 01:12:08\n",
      "2019-10-21 19:57:07\n",
      "2019-10-17 21:01:22\n",
      "2019-10-16 03:22:02\n",
      "2019-10-15 22:58:02\n",
      "2019-10-11 18:44:18\n",
      "2019-10-09 13:30:49\n",
      "2019-10-04 16:04:13\n",
      "2019-10-01 22:21:41\n",
      "2019-09-30 12:20:58\n",
      "2019-09-27 02:48:45\n",
      "2019-09-24 19:19:36\n",
      "2019-09-22 20:13:41\n",
      "2019-09-21 15:16:27\n",
      "2019-09-21 01:50:45\n",
      "2019-09-18 16:07:51\n",
      "2019-09-14 22:08:15\n",
      "2019-09-13 03:13:40\n",
      "2019-09-13 00:57:12\n",
      "JoeBiden\n",
      "2019-12-06 23:59:00\n",
      "2019-12-04 20:20:00\n",
      "2019-12-02 00:55:00\n",
      "2019-11-29 15:37:30\n",
      "2019-11-25 22:40:00\n",
      "2019-11-22 16:15:00\n",
      "2019-11-21 03:13:03\n",
      "2019-11-20 17:24:06\n",
      "2019-11-17 18:32:00\n",
      "2019-11-15 01:00:00\n",
      "2019-11-12 21:32:00\n",
      "2019-11-11 00:07:00\n",
      "2019-11-08 00:23:00\n",
      "2019-11-05 19:00:00\n",
      "2019-11-03 02:41:27\n",
      "2019-11-01 16:45:00\n",
      "2019-10-30 18:44:14\n",
      "2019-10-28 20:17:44\n",
      "2019-10-26 16:24:46\n",
      "2019-10-24 18:17:00\n",
      "2019-10-22 18:15:00\n",
      "2019-10-19 16:43:42\n",
      "2019-10-17 17:22:00\n",
      "2019-10-16 02:24:54\n",
      "2019-10-15 23:36:37\n",
      "2019-10-13 17:20:26\n",
      "2019-10-11 00:45:00\n",
      "2019-10-09 18:26:57\n",
      "2019-10-07 19:35:00\n",
      "2019-10-05 23:45:00\n",
      "2019-10-03 17:40:00\n",
      "2019-09-30 21:53:00\n",
      "2019-09-27 22:58:26\n",
      "2019-09-25 00:30:00\n",
      "2019-09-23 00:41:00\n",
      "2019-09-20 22:54:10\n",
      "2019-09-18 17:17:24\n",
      "2019-09-15 21:42:00\n",
      "2019-09-13 16:45:00\n",
      "2019-09-13 01:41:16\n"
     ]
    }
   ],
   "source": [
    "startDate =   datetime.datetime(2019, 9, 13, 0, 0, 0)\n",
    "# startDate =   datetime.datetime(2019, 11, 1, 0, 0, 0)\n",
    "endDate = datetime.datetime(2019, 11, 23, 0, 0, 0)\n",
    "tweets = {}\n",
    "cand_handles = ['AndrewYang', 'ewarren', 'PeteButtigieg', 'BernieSanders', \n",
    "                'MichaelBennet', 'amyklobuchar', 'KamalaHarris', 'TulsiGabbard', \n",
    "                'JulianCastro', 'CoryBooker', 'JoeBiden']\n",
    "\n",
    "for cand_name in cand_handles:\n",
    "    print(cand_name)\n",
    "    cand_tweets = []\n",
    "    tweets[cand_name] = cand_tweets\n",
    "    try:\n",
    "        tmpTweets = api.user_timeline(cand_name, tweet_mode='extended')\n",
    "    except tweepy.TweepError:\n",
    "        print(\"tweepyError 2\")\n",
    "        time.sleep(60 * 15)\n",
    "        continue\n",
    "    except StopIteration:\n",
    "        break\n",
    "    for t in tmpTweets:\n",
    "        if t.created_at < endDate and t.created_at > startDate:\n",
    "            cand_tweets.append(t)\n",
    "    if len(cand_tweets) > 0:\n",
    "        print(cand_tweets)\n",
    "    try:\n",
    "        while (tmpTweets[-1].created_at > startDate):\n",
    "            print(tmpTweets[-1].created_at)\n",
    "            tmpTweets = api.user_timeline(cand_name, max_id = tmpTweets[-1].id, tweet_mode='extended')\n",
    "            for ti in tmpTweets:\n",
    "                if ti.created_at < endDate and ti.created_at > startDate:\n",
    "                    t = ti._json\n",
    "                    if t['full_text'].startswith('RT @'):\n",
    "                        # skip if a retweet\n",
    "                        continue\n",
    "                        \n",
    "                    tw_obj = Tweet(t['full_text'], get_tweet_time(t['created_at']), cand_name)\n",
    "                    if 'media' in t['entities']:\n",
    "                        tw_obj.contains_media()\n",
    "                    if len(t['entities']['urls']) > 0:\n",
    "                        tw_obj.contains_link()\n",
    "                    if t['in_reply_to_screen_name'] and t['in_reply_to_screen_name'] != cand_name:\n",
    "                        tw_obj.is_response()\n",
    "                    cand_tweets.append(tw_obj)\n",
    "    except tweepy.TweepError:\n",
    "        time.sleep(60 * 15)\n",
    "        print(\"tweepyError 2\")\n",
    "        continue\n",
    "#     except:\n",
    "#         print(len(cand_tweets))\n",
    "#         print(len(tmpTweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AndrewYang    208\n",
      "ewarren    976\n",
      "PeteButtigieg    235\n",
      "BernieSanders    576\n",
      "MichaelBennet    359\n",
      "amyklobuchar    375\n",
      "KamalaHarris    400\n",
      "TulsiGabbard    157\n",
      "JulianCastro    606\n",
      "CoryBooker    303\n",
      "JoeBiden    484\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for k in cand_handles:    \n",
    "    warren_tweets = tweets[k]\n",
    "    zzzzzzzzzzz = 0\n",
    "    for i in range(len(warren_tweets)):\n",
    "        if not warren_tweets[i].raw_text.lower().startswith('rt') and not warren_tweets[i]._clean_text.count(\" \") < 15:\n",
    "    #         print(warren_tweets[i].raw_text)\n",
    "    #         print(warren_tweets[i].get_sentiment()[0])\n",
    "\n",
    "            zzzzzzzzzzz += 1\n",
    "    print(k + \"    \" + str(zzzzzzzzzzz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_sentiment(cand):\n",
    "    global tweets\n",
    "    cand_t = tweets[cand]\n",
    "    sent_sum = float(0)\n",
    "    num_counted = float(0)\n",
    "    for i in range(len(cand_t)):\n",
    "        if not (cand_t[i]._clean_text).count(\" \") < 15:\n",
    "            sent_sum += cand_t[i].get_sentiment()[0]\n",
    "            num_counted += 1\n",
    "    return sent_sum/num_counted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "poll_dates = []\n",
    "time_tweets = {}\n",
    "    \n",
    "for j in polls:\n",
    "    poll_dates.append(j.start_date)\n",
    "poll_dates.append(datetime.date(2020, 10, 10)) # dummy time to avoid null pointer in next for loop\n",
    "poll_dates.sort()\n",
    "\n",
    "curr_poll = 0\n",
    "for j in tweets:\n",
    "    time_tweets[j] = {}\n",
    "    for i in tweets[j]:\n",
    "        if curr_poll != len(polls)-1 and i.date >= polls[curr_poll+1].end_date:\n",
    "            curr_poll += 1\n",
    "        if polls[curr_poll] not in time_tweets[j]:\n",
    "            time_tweets[j][polls[curr_poll]] = []\n",
    "        time_tweets[j][polls[curr_poll]].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[datetime.date(2019, 9, 13), datetime.date(2019, 9, 14), datetime.date(2019, 9, 15), datetime.date(2019, 9, 16), datetime.date(2019, 9, 19), datetime.date(2019, 9, 20), datetime.date(2019, 9, 21), datetime.date(2019, 9, 22), datetime.date(2019, 9, 22), datetime.date(2019, 9, 23), datetime.date(2019, 9, 23), datetime.date(2019, 9, 26), datetime.date(2019, 9, 28), datetime.date(2019, 9, 30), datetime.date(2019, 10, 4), datetime.date(2019, 10, 6), datetime.date(2019, 10, 6), datetime.date(2019, 10, 6), datetime.date(2019, 10, 7), datetime.date(2019, 10, 11), datetime.date(2019, 10, 13), datetime.date(2019, 10, 15), datetime.date(2019, 10, 16), datetime.date(2019, 10, 16), datetime.date(2019, 10, 17), datetime.date(2019, 10, 17), datetime.date(2019, 10, 18), datetime.date(2019, 10, 20), datetime.date(2019, 10, 21), datetime.date(2019, 10, 21), datetime.date(2019, 10, 21), datetime.date(2019, 10, 23), datetime.date(2019, 10, 24), datetime.date(2019, 10, 27), datetime.date(2019, 10, 27), datetime.date(2019, 10, 27), datetime.date(2019, 10, 27), datetime.date(2019, 10, 28), datetime.date(2019, 10, 29), datetime.date(2019, 10, 30), datetime.date(2019, 11, 1), datetime.date(2019, 11, 3), datetime.date(2019, 11, 4), datetime.date(2019, 11, 10), datetime.date(2019, 11, 11), datetime.date(2019, 11, 11), datetime.date(2019, 11, 16), datetime.date(2019, 11, 17), datetime.date(2019, 11, 17), datetime.date(2020, 10, 10)]\n"
     ]
    }
   ],
   "source": [
    "print(poll_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cand_pos(c, p):\n",
    "    for po in c.polls:\n",
    "        if po[0] == p:\n",
    "            return po[1]\n",
    "    return null # should never happen\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'cand_name' : [], 'sentiment' : [], 'other_mentions' : [], 'topic' : [], 'poll_position': []})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cand_sentiments = {}\n",
    "sentiment_nums = {}\n",
    "for j in time_tweets:\n",
    "    cand_sentiments[j] = {}\n",
    "    sentiment_nums[j] = []\n",
    "    for i in time_tweets[j]:\n",
    "        df = df.append({'cand_name': j , 'sentiment' : i.get_sentiment(), \n",
    "                        'other_mentions': i.get_other_mentions(), 'topic': i.get_topic(),\n",
    "                       'poll_position': } , ignore_index=True)\n",
    "#         sent = avg_sentiment(j)\n",
    "        cand_sentiments[j][i] = sent\n",
    "        sentiment_nums[j].append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: create table where y value is tweeters standing in most recent poll at the date of the tweet\n",
    "# x values are sentiment of a tweet, mentions, and topic\n",
    "# run regression on all of the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cand_sentiments\n",
    "\n",
    "sentiment_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImage(path):\n",
    "    if path == 'images/sanders.png':\n",
    "        return OffsetImage(plt.imread(path), zoom = 0.03, interpolation='gaussian')\n",
    "    elif path == 'images/bennet.png':\n",
    "        return OffsetImage(plt.imread(path), zoom = 0.08, interpolation='gaussian')\n",
    "    else:\n",
    "        return OffsetImage(plt.imread(path), zoom = 0.1, interpolation='gaussian')\n",
    "\n",
    "paths = ['images/bennet.png',\n",
    "        'images/biden.png',\n",
    "        'images/booker.png',\n",
    "        'images/buttigieg.png',\n",
    "        'images/castro.png',\n",
    "        'images/gabbard.png',\n",
    "        'images/harris.png',\n",
    "        'images/klobuchar.png',\n",
    "        'images/sanders.png',\n",
    "        'images/warren.png',\n",
    "        'images/yang.png']\n",
    "\n",
    "x = [i+1 for i in range(len(paths))]\n",
    "y = sentiment_nums\n",
    "# x = [0,1,2,3,4]\n",
    "# y = [0,1,2,3,4]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x, y, color = \"white\")\n",
    "plt.xticks(np.arange(1, len(paths)+1, 1), np.arange(len(paths), 0, -1))\n",
    "y = []\n",
    "\n",
    "# for x0, y0, path in zip(x, y,paths):\n",
    "for i in range(len(paths)):\n",
    "    candidate_name = most_recent_rankings[i]\n",
    "    path_name = \"images/\" + candidate_name + \".png\"\n",
    "#     ab = AnnotationBbox(getImage(path), (x0, y0), frameon=False) # , box_alignment=(0.3,0.3))\n",
    "    ab = AnnotationBbox(getImage(path_name), (x[i], \n",
    "                            cand_sentiments[last_name_to_handle[candidate_name]]), frameon=False) # , box_alignment=(0.3,0.3))\n",
    "    ax.add_artist(ab)\n",
    "    y.append(cand_sentiments[last_name_to_handle[candidate_name]])\n",
    "\n",
    "# plot line of best fit\n",
    "# plt.plot(np.unique(x), np.poly1d(np.polyfit(x, y, 1))(np.unique(x)))\n",
    "    \n",
    "caption = \"\"\"The ranking in the most recent polls is based upon the current RealClearPolitics (RCP) average.\n",
    "            Tweet sentiment is calculated using the TextBlob Python package and is conducted on all tweets \n",
    "            of more than 30 words between Sep 2 and Nov 16 of 2019. 30 words was chosen to make the sentiment \n",
    "            analysis more accurate. Sentiment is calculated on a continuous scale from -1 (negative) to 1 (positive),\n",
    "            with a score of 0 having a neutral sentiment. Bloomberg and Steyer are excluded from this analysis because\n",
    "            of their late entry into the race.\"\"\"\n",
    "\n",
    "plt.xlabel(\"Position in Latest Polls\")\n",
    "plt.ylabel(\"Average Tweet Sentiment\")\n",
    "plt.title(\"Average Tweet Sentiment vs. Position in Polls\")\n",
    "fig.text(.5, -.2, caption, ha='center', fontdict={'size': 7})\n",
    "\n",
    "\n",
    "plt.savefig('my_figure_with_best_fit.pdf', bbox_inches='tight', dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model fit for above graph\n",
    "x_amy = x.copy()\n",
    "del x_amy[3]\n",
    "y_amy = y.copy()\n",
    "del y_amy[3]\n",
    "slope, intercept, r_value, p_value, std_err = linregress(x,y)\n",
    "slope1, intercept1, r_value1, p_value1, std_err1 = linregress(x_amy,y_amy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import iqr, linregress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outlier check for above graph\n",
    "# q3 = np.quantile(y, 0.75)\n",
    "# iqr = iqr(y)\n",
    "for i in range(len(y)):\n",
    "    if y[i] < 0:\n",
    "        print(i)\n",
    "        \n",
    "print(y[-1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lem_data = []\n",
    "    \n",
    "def get_global_topics(cand):\n",
    "    global tweets\n",
    "    global lem_data\n",
    "    lem_data.append([])\n",
    "    cand_t = tweets[cand]\n",
    "    sent_sum = float(0)\n",
    "    num_counted = float(0)\n",
    "    for i in range(len(cand_t)):\n",
    "        if not (cand_t[i]._clean_text).count(\" \") < 15:\n",
    "            lem_data[-1] = lem_data[-1] + cand_t[i].data_lemmatized\n",
    "\n",
    "for i in tweets:\n",
    "    get_global_topics(i)\n",
    "            \n",
    "id2word = corpora.Dictionary(lem_data)\n",
    "\n",
    "# Create Corpus\n",
    "texts = lem_data\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                   id2word=id2word,\n",
    "                                   num_topics=10, \n",
    "                                   random_state=100,\n",
    "                                   update_every=1,\n",
    "                                   chunksize=100,\n",
    "                                   passes=10,\n",
    "                                   alpha='auto',\n",
    "                                   per_word_topics=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
